Feb, 2017

A) training

Called with trainingFile.conll and archiveFile.zip

1. init classes Archivator(archiveFile.zip, dirs) and Trainer()

2. call trainer main class:
	trainer.createAndTrainWithSplittingFromDisk(algorithm,trainFile,
				splitModelsDir, alphabetFileParser,alphabetFileLabeler,splitFile);
	with
	trainFile = trainingFile.conll
	String splitModelsDir = "splitModels";
	String algorithm = "covington";
	String splitFile = "temp/split.txt";
	String alphabetFileParser = "temp/alphaParser.txt";
	String alphabetFileLabeler = "temp/alphaLabeler.txt";
	
-	Data d = new Data(inputFile, true);
	-	internalize CONLL data in 2-Dim sentences; max 0-12 conll columns are considered
		-	can be changed in de.dfki.lt.mdparser.data.Data.infoSize = 12 
			-> I changed value to 10/14; training/testing seems to work
		-	useful for adding additional CONLL information
		-	currently sets COLUMNs 6, 7, 8, 9 (test) and 8, 9 (train) to "_"
		-	if other information should be used, we need adapt this here
		
-	FeatureExtractor fe = new FeatureExtractor();
	-	activate the feature template functions
	-	will later be used to create the feature vectors for specific training instances
	-	hard-codes access of CONLL format
	-	can be extended to use also other CONLL information or other data sources
	
-	select fm = new CovingtonFeatureModel(alphaParser, fe);
	-	provides template instantiation methods for Covington parsing strategy
	-	these are later applied on training/testing instances later
	-	NOTE: This can be investigated to improve parser

-	select parsing strategy: so far:
	pa = new CovingtonAlgorithm()

-	for each training example, call selected parser:
	-	pa.processCombined(sent, fm, noLabels::=false);

-	now split LibLienar training file
	HIERIX


	
B) Parsing algorithms

NOTE:
Parsing algorithm is used in training and testing.

In training it is used for oracle, where the gold dependency tree is used as "model"
In testing it is used for applying a model to predict transitions.

Main function - in twp versions - is processCombined()

B.1) Covington

-	compute all possible node pairs from j:=1 downto i:=j-i
	-	what puzzles me: sometime, I do not see all edge spans when using system.out.println()
	
-	for each node pair, check whether (j,label,i) or (i,label,j) is permissible
	-		this.isSingleHead(heads) 
			&& this.isNotReflexive() 
			&& this.notIntroducingCycle(heads) 	-> 	checks whole subtree
			&& this.isNotImproperRoot() 
			&& this.isProjective(heads)			->	checks whole subtree
	-	if permissible
		-	create feature vector for transition
			FeatureVector fvParser = fm2.applyCombined(ps, true, noLabels);	
		-	get label instance: use CONLL columns 6 & 7
			String label = findOutCorrectLabelCombined(j, i, sentArray);
			which is an instance of: left, right, shift, terminate
		-	NOTE: this realizes the actual oracle
			-	CAN this be approved ? e.g., a different ordering
	-	training sentence is now a vector of label-edgeFeatureVectors
	-	update alphabet index and create an integer representation of symbolic feature vector
		-	each line a token feature vector
		-	sentence via newline
		-	store all in file split0/

B.2) Stack

A transition-based parser: use "stack" instead of "covington"

Uses same feature extraction class as "covington": 
1.) FeatureExtractor fe = new FeatureExtractor();

  Returns a set of feature generation methods, which are applied on current token of sentence and eventually other tokens in context.
  When applied on current data, return a feature as a specific string of form "featureName=value"

2.) Then specific stack parser is initialized:

ParsingAlgorithm pa = null;
    if (algorithm.equals("stack")) {
      fm = new StackFeatureModel(alphaParser,fe);
      pa = new StackAlgorithm();
    }

2.1) StackFeatureModel: Provides a method applyCombined() which is called with a current state StackParserState:
      - a tuple of <token stack, token buffer, sentence, depTree> 
      - it selects the relevant stack/buffer elements
      - and applies all feature templates on current tokens of stack/buffer and sentence
      - and creates a feature vector for the sentence  
    

3.) Then, on each training instance, during training, feature vector is created:

      // GN: call the parser on each training example to "re-play" the parser configurations
      //     and to compute the operations in form of a list of feature vectors for each state.
      //     this means that all feature functions are applied on the parsed sentence by applying
      //     the feature model in the training mode.
      //     the result is then a list of parser states in form of feature vectors whose values are based
      //     one the specific training example
      List<FeatureVector> parserList = pa.processCombined(sent, fm, noLabels);
      
      
      
Problems with stack parser:

It crashes for 

//   mdpTester.trainAndTest("resources/input/ptb3-std-training.conll", "ptb3-std.zip", 
//        "resources/input/ptb3-std-test.conll", "resources/input/ptb3-std-result.conll");
    
    mdpTester.trainAndTest("resources/input/german_tiger_train.conll", "tiger.zip", 
        "resources/input/german_tiger_test.conll", "resources/input/german_tiger_result.conll");

//    mdpTester.trainAndTest("resources/input/en-train-2009.conll", "en-2009.zip", 
//        "resources/input/en-test-2009.conll", "resources/input/en-result-2009.conll");

with 

Exception in thread "main" java.io.EOFException: unexpected EOF
  at de.bwaldvogel.liblinear.Linear.loadModel(Linear.java:299)
  at de.bwaldvogel.liblinear.Linear.loadModel(Linear.java:321)
  at de.dfki.lt.mdparser.parser.Trainer.restoreModels(Trainer.java:439)
  at de.dfki.lt.mdparser.parser.Trainer.recreateOneAlphabetAndAdjustModels(Trainer.java:430)
  at de.dfki.lt.mdparser.parser.Trainer.createAndTrainWithSplittingFromDisk(Trainer.java:423)
  at de.dfki.lt.mdparser.caller.MDPtrainer.trainer(MDPtrainer.java:78)
  at standard.MDPtester.trainLanguage(MDPtester.java:27)
  at standard.MDPtester.trainAndTest(MDPtester.java:46)
  at standard.MDPtester.main(MDPtester.java:58)
  
  it works for
  
      mdpTester.trainAndTest("resources/input/de-train-2009.conll", "de-2009.zip", 
        "resources/input/de-test-2009.conll", "resources/input/de-result-2009.conll");
        
        

C) What are the differences and commonalities ?

Difference: 
parsing strategy
specific applyCombine methods

At least for de-test-2009.conll: 
covington is about 4% accuracy better than stack, but about factor 2 slower

Commonalities:

feature templates
feature vector representation
learning
parallel processing
CONLL format used

D) Feaqture extraction and representation

More precisely, how CONLL format and feature templates and instantiation interact, 
so that it can be generalized eventually for AMR or in order to improve MDP by integrating morphology etc.

